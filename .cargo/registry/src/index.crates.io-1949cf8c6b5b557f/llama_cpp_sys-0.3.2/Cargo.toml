# THIS FILE IS AUTOMATICALLY GENERATED BY CARGO
#
# When uploading crates to the registry Cargo will automatically
# "normalize" Cargo.toml files for maximal compatibility
# with all versions of Cargo and also rewrite `path` dependencies
# to registry (e.g., crates.io) dependencies.
#
# If you are reading this file be aware that the original Cargo.toml
# will likely look very different (and much more reasonable).
# See Cargo.toml.orig for the original contents.

[package]
edition = "2021"
name = "llama_cpp_sys"
version = "0.3.2"
authors = [
    "Dakota Thompson <me@scriptis.net>",
    "Pedro Valente <pedro.amaral.valente@gmail.com>",
]
links = "llama"
exclude = [
    "thirdparty/**/tests",
    "thirdparty/**/scripts",
    "thirdparty/**/examples",
    "thirdparty/**/prompts",
    "thirdparty/**/gguf-py",
    "thirdparty/**/.devops",
    "thirdparty/**/docs",
    "thirdparty/**/media",
]
publish = true
description = "Automatically-generated bindings to llama.cpp's C API"
readme = "README.md"
license = "MIT OR Apache-2.0"
repository = "https://github.com/edgenai/llama_cpp-rs"

[dependencies.ash]
version = "0.37.3"
features = ["linked"]
optional = true
default-features = false

[dependencies.cudarc]
version = "0.10.0"
features = ["cublaslt"]
optional = true

[dependencies.link-cplusplus]
version = "1.0.9"

[build-dependencies.bindgen]
version = "0.69.4"

[build-dependencies.cc]
version = "1.0.83"
features = ["parallel"]

[build-dependencies.once_cell]
version = "1.19.0"

[features]
accel = []
avx = []
avx2 = []
avx512 = []
avx512_vmbi = []
avx512_vnni = []
blas = []
clblast = []
compat = []
cuda = ["dep:cudarc"]
cuda_dmmv = ["cuda"]
cuda_f16 = ["cuda"]
cuda_mmq = ["cuda"]
default = [
    "compat",
    "native",
]
f16c = []
fma = []
hipblas = []
metal = []
mpi = []
native = [
    "avx",
    "avx2",
    "fma",
    "f16c",
    "accel",
]
vulkan = ["dep:ash"]
